
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{01\_homework\_knn}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \textbf{Student}: Denys Lazarenko\\
\textbf{Enrollment number}: 03708891

\textbf{Student}: Jakob Huber\\
\textbf{Enrollment number}: 03648362

\hypertarget{problem-1}{%
\subsubsection{Problem 1}\label{problem-1}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{class} \PY{n+nc}{Node}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{prediction} \PY{o}{=} \PY{k+kc}{None}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{gini} \PY{o}{=} \PY{k+kc}{None}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{j\PYZus{}ast} \PY{o}{=} \PY{k+kc}{None}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{t\PYZus{}ast} \PY{o}{=} \PY{k+kc}{None}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{right} \PY{o}{=} \PY{k+kc}{None}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{left} \PY{o}{=} \PY{k+kc}{None}
                
        \PY{n}{NodeType} \PY{o}{=} \PY{n}{NewType}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{NodeType}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{Node}\PY{p}{)}
                
        \PY{k}{class} \PY{n+nc}{Tree}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{node} \PY{o}{=} \PY{k+kc}{None}
            
            \PY{n+nd}{@staticmethod}
            \PY{k}{def} \PY{n+nf}{gini}\PY{p}{(}\PY{n}{probs}\PY{p}{)} \PY{o}{\PYZhy{}}\PY{o}{\PYZgt{}} \PY{n+nb}{float}\PY{p}{:}
                \PY{k}{return} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{probs}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}
            
            \PY{n+nd}{@staticmethod}
            \PY{k}{def} \PY{n+nf}{get\PYZus{}probabilities}\PY{p}{(}\PY{n}{y}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{)} \PY{o}{\PYZhy{}}\PY{o}{\PYZgt{}} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{:}
                \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{counts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{return\PYZus{}counts}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{true\PYZus{}divide}\PY{p}{(}\PY{n}{counts}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{counts}\PY{p}{)}\PY{p}{)}
            
            \PY{n+nd}{@staticmethod}
            \PY{k}{def} \PY{n+nf}{split}\PY{p}{(}\PY{n}{D}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{,} \PY{n}{y}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{)} \PY{o}{\PYZhy{}}\PY{o}{\PYZgt{}} \PY{n+nb}{tuple}\PY{p}{:}
                \PY{n}{n}\PY{p}{,} \PY{n}{m} \PY{o}{=} \PY{n}{D}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{D}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
                \PY{n}{gini\PYZus{}min}\PY{p}{,} \PY{n}{j\PYZus{}ast}\PY{p}{,} \PY{n}{t\PYZus{}ast}\PY{p}{,} \PY{n}{D\PYZus{}l}\PY{p}{,} \PY{n}{D\PYZus{}r} \PY{p}{,} \PY{n}{y\PYZus{}l}\PY{p}{,} \PY{n}{y\PYZus{}r} \PY{o}{=} \PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{inf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{]} \PY{o}{+} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]}\PY{o}{*}\PY{l+m+mi}{6}
                \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{m}\PY{p}{)}\PY{p}{:}
                    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n}\PY{p}{)}\PY{p}{:}
                        \PY{n}{trashhold} \PY{o}{=} \PY{n}{D}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]}
                        \PY{n}{indexes} \PY{o}{=} \PY{n}{D}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{j}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{n}{trashhold}
                        \PY{n}{probs\PYZus{}le}\PY{p}{,} \PY{n}{probs\PYZus{}ge} \PY{o}{=} \PY{n}{Tree}\PY{o}{.}\PY{n}{get\PYZus{}probabilities}\PY{p}{(}\PY{n}{y}\PY{p}{[}\PY{n}{indexes}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{Tree}\PY{o}{.}\PY{n}{get\PYZus{}probabilities}\PY{p}{(}\PY{n}{y}\PY{p}{[}\PY{o}{\PYZti{}}\PY{n}{indexes}\PY{p}{]}\PY{p}{)}
                        \PY{n}{gini\PYZus{}le}\PY{p}{,} \PY{n}{gini\PYZus{}ge} \PY{o}{=} \PY{n}{Tree}\PY{o}{.}\PY{n}{gini}\PY{p}{(}\PY{n}{probs\PYZus{}le}\PY{p}{)}\PY{p}{,} \PY{n}{Tree}\PY{o}{.}\PY{n}{gini}\PY{p}{(}\PY{n}{probs\PYZus{}ge}\PY{p}{)}
                        \PY{k}{if} \PY{p}{(}\PY{n}{gini\PYZus{}le} \PY{o}{+} \PY{n}{gini\PYZus{}ge}\PY{p}{)} \PY{o}{\PYZlt{}} \PY{n}{gini\PYZus{}min}\PY{p}{:}
                            \PY{n}{gini\PYZus{}min} \PY{o}{=} \PY{n}{gini\PYZus{}le} \PY{o}{+} \PY{n}{gini\PYZus{}ge}
                            \PY{n}{j\PYZus{}ast} \PY{o}{=} \PY{n}{j}
                            \PY{n}{t\PYZus{}ast} \PY{o}{=} \PY{n}{trashhold}
                            \PY{n}{D\PYZus{}l} \PY{o}{=} \PY{n}{D}\PY{p}{[}\PY{n}{indexes}\PY{p}{]}
                            \PY{n}{D\PYZus{}r} \PY{o}{=} \PY{n}{D}\PY{p}{[}\PY{o}{\PYZti{}}\PY{n}{indexes}\PY{p}{]}
                            \PY{n}{y\PYZus{}l} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{indexes}\PY{p}{]}
                            \PY{n}{y\PYZus{}r} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{o}{\PYZti{}}\PY{n}{indexes}\PY{p}{]}
                \PY{k}{return} \PY{n}{j\PYZus{}ast}\PY{p}{,} \PY{n}{t\PYZus{}ast}\PY{p}{,} \PY{n}{D\PYZus{}l}\PY{p}{,} \PY{n}{D\PYZus{}r}\PY{p}{,} \PY{n}{y\PYZus{}l}\PY{p}{,} \PY{n}{y\PYZus{}r}\PY{p}{,} \PY{n}{gini\PYZus{}min}
                
            \PY{n+nd}{@staticmethod}
            \PY{k}{def} \PY{n+nf}{fitTree}\PY{p}{(}\PY{n}{node}\PY{p}{:} \PY{n}{NodeType}\PY{p}{,} \PY{n}{D}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{,} \PY{n}{y}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{,} \PY{n}{depth}\PY{p}{:}\PY{n+nb}{int}\PY{p}{)} \PY{o}{\PYZhy{}}\PY{o}{\PYZgt{}} \PY{n}{NodeType}\PY{p}{:}
                \PY{n}{node}\PY{o}{.}\PY{n}{prediction} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{y}\PY{p}{)}
                \PY{k}{if} \PY{p}{(}\PY{n}{depth} \PY{o}{==} \PY{l+m+mi}{2}\PY{p}{)} \PY{o+ow}{or} \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{node}\PY{o}{.}\PY{n}{prediction}\PY{p}{)} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
                    \PY{k}{return} \PY{n}{node}
                \PY{k}{else}\PY{p}{:}
                    \PY{n}{j\PYZus{}ast}\PY{p}{,} \PY{n}{t\PYZus{}ast}\PY{p}{,} \PY{n}{D\PYZus{}l}\PY{p}{,} \PY{n}{D\PYZus{}r}\PY{p}{,} \PY{n}{y\PYZus{}l}\PY{p}{,} \PY{n}{y\PYZus{}r}\PY{p}{,} \PY{n}{gini\PYZus{}min} \PY{o}{=} \PY{n}{Tree}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{D}\PY{p}{,} \PY{n}{y}\PY{p}{)}
                    \PY{n}{node}\PY{o}{.}\PY{n}{gini} \PY{o}{=} \PY{n}{gini\PYZus{}min}
                    \PY{n}{node}\PY{o}{.}\PY{n}{j\PYZus{}ast} \PY{o}{=} \PY{n}{j\PYZus{}ast}
                    \PY{n}{node}\PY{o}{.}\PY{n}{t\PYZus{}ast} \PY{o}{=} \PY{n}{t\PYZus{}ast}
                    \PY{n}{node}\PY{o}{.}\PY{n}{left} \PY{o}{=} \PY{n}{Tree}\PY{o}{.}\PY{n}{fitTree}\PY{p}{(}\PY{n}{Node}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{D\PYZus{}l}\PY{p}{,} \PY{n}{y\PYZus{}l}\PY{p}{,} \PY{n}{depth} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
                    \PY{n}{node}\PY{o}{.}\PY{n}{right} \PY{o}{=} \PY{n}{Tree}\PY{o}{.}\PY{n}{fitTree}\PY{p}{(}\PY{n}{Node}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{D\PYZus{}r}\PY{p}{,} \PY{n}{y\PYZus{}r}\PY{p}{,} \PY{n}{depth} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
                    \PY{k}{return} \PY{n}{node}
            
            \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{node} \PY{o}{=} \PY{n}{Node}\PY{p}{(}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{node} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fitTree}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{node}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{depth}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
                
            \PY{n+nd}{@staticmethod}
            \PY{k}{def} \PY{n+nf}{predict\PYZus{}element}\PY{p}{(}\PY{n}{node}\PY{p}{,} \PY{n}{x\PYZus{}new}\PY{p}{)}\PY{p}{:}
                \PY{k}{if} \PY{p}{(}\PY{n}{node}\PY{o}{.}\PY{n}{right} \PY{o}{==} \PY{k+kc}{None}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{node}\PY{o}{.}\PY{n}{left} \PY{o}{==} \PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
                    \PY{k}{return} \PY{n+nb}{max}\PY{p}{(}\PY{n}{node}\PY{o}{.}\PY{n}{prediction}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{n}{node}\PY{o}{.}\PY{n}{prediction}\PY{o}{.}\PY{n}{get}\PY{p}{)}
                \PY{k}{if} \PY{n}{x\PYZus{}new}\PY{p}{[}\PY{n}{node}\PY{o}{.}\PY{n}{j\PYZus{}ast}\PY{p}{]} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{node}\PY{o}{.}\PY{n}{t\PYZus{}ast}\PY{p}{:}
                    \PY{k}{return} \PY{n}{Tree}\PY{o}{.}\PY{n}{predict\PYZus{}element}\PY{p}{(}\PY{n}{node}\PY{o}{.}\PY{n}{left}\PY{p}{,} \PY{n}{x\PYZus{}new}\PY{p}{)}
                \PY{k}{elif} \PY{n}{x\PYZus{}new}\PY{p}{[}\PY{n}{node}\PY{o}{.}\PY{n}{j\PYZus{}ast}\PY{p}{]} \PY{o}{\PYZgt{}} \PY{n}{node}\PY{o}{.}\PY{n}{t\PYZus{}ast}\PY{p}{:}
                    \PY{k}{return} \PY{n}{Tree}\PY{o}{.}\PY{n}{predict\PYZus{}element}\PY{p}{(}\PY{n}{node}\PY{o}{.}\PY{n}{right}\PY{p}{,} \PY{n}{x\PYZus{}new}\PY{p}{)}
            
            \PY{k}{def} \PY{n+nf}{predict}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}new}\PY{p}{)}\PY{p}{:}
                \PY{n}{result} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
                \PY{k}{for} \PY{n}{x\PYZus{}new} \PY{o+ow}{in} \PY{n}{X\PYZus{}new}\PY{p}{:}
                    \PY{n}{result} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{result}\PY{p}{,} \PY{n}{Tree}\PY{o}{.}\PY{n}{predict\PYZus{}element}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{node}\PY{p}{,} \PY{n}{x\PYZus{}new}\PY{p}{)}\PY{p}{)}
                \PY{k}{return} \PY{n}{result}
\end{Verbatim}


    \includegraphics{./test-output/round-table.gv.png}

    \hypertarget{problem-2}{%
\subsubsection{Problem 2}\label{problem-2}}

    \(\hat{y_a} = 1\)\\
\(\hat{y_b} = 0\)

    \(p(c = 1 | x_a; T) = 1\)\\
\(p(c = 0 | x_b; T) = \frac{5}{7}\) and
\(p(c = 2 | x_b; T) = \frac{2}{7}\)

    \hypertarget{problem-3}{%
\subsubsection{Problem 3}\label{problem-3}}

    \hypertarget{programming-assignment-1-k-nearest-neighbors-classification}{%
\section{Programming assignment 1: k-Nearest Neighbors
classification}\label{programming-assignment-1-k-nearest-neighbors-classification}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{datasets}\PY{p}{,} \PY{n}{model\PYZus{}selection}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline  
\end{Verbatim}


    \hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

For those of you new to Python, there are lots of tutorials online, just
pick whichever you like best :)

If you never worked with Numpy or Jupyter before, you can check out
these guides * https://docs.scipy.org/doc/numpy-dev/user/quickstart.html
* http://jupyter.readthedocs.io/en/latest/

    \hypertarget{your-task}{%
\subsection{Your task}\label{your-task}}

In this notebook code to perform k-NN classification is provided.
However, some functions are incomplete. Your task is to fill in the
missing code and run the entire notebook.

In the beginning of every function there is docstring, which specifies
the format of input and output. Write your code in a way that adheres to
it. You may only use plain python and \texttt{numpy} functions (i.e.~no
scikit-learn classifiers).

    \hypertarget{exporting-the-results-to-pdf}{%
\subsection{Exporting the results to
PDF}\label{exporting-the-results-to-pdf}}

Once you complete the assignments, export the entire notebook as PDF and
attach it to your homework solutions. The best way of doing that is 1.
Run all the cells of the notebook. 2. Download the notebook in HTML
(click File \textgreater{} Download as \textgreater{} .html) 3. Convert
the HTML to PDF using e.g.~https://www.sejda.com/html-to-pdf or
\texttt{wkhtmltopdf} for Linux
(\href{https://www.cyberciti.biz/open-source/html-to-pdf-freeware-linux-osx-windows-software/}{tutorial})
4. Concatenate your solutions for other tasks with the output of Step 3.
On a Linux machine you can simply use \texttt{pdfunite}, there are
similar tools for other platforms too. You can only upload a single PDF
file to Moodle.

This way is preferred to using \texttt{nbconvert}, since
\texttt{nbconvert} clips lines that exceed page width and makes your
code harder to grade.

    \hypertarget{load-dataset}{%
\subsection{Load dataset}\label{load-dataset}}

The iris data set
(https://en.wikipedia.org/wiki/Iris\_flower\_data\_set) is loaded and
split into train and test parts by the function \texttt{load\_dataset}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k}{def} \PY{n+nf}{load\PYZus{}dataset}\PY{p}{(}\PY{n}{split}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Load and split the dataset into training and test parts.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Parameters}
        \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
        \PY{l+s+sd}{    split : float in range (0, 1)}
        \PY{l+s+sd}{        Fraction of the data used for training.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Returns}
        \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
        \PY{l+s+sd}{    X\PYZus{}train : array, shape (N\PYZus{}train, 4)}
        \PY{l+s+sd}{        Training features.}
        \PY{l+s+sd}{    y\PYZus{}train : array, shape (N\PYZus{}train)}
        \PY{l+s+sd}{        Training labels.}
        \PY{l+s+sd}{    X\PYZus{}test : array, shape (N\PYZus{}test, 4)}
        \PY{l+s+sd}{        Test features.}
        \PY{l+s+sd}{    y\PYZus{}test : array, shape (N\PYZus{}test)}
        \PY{l+s+sd}{        Test labels.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{dataset} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{load\PYZus{}iris}\PY{p}{(}\PY{p}{)}
            \PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{model\PYZus{}selection}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{split}\PY{p}{)}\PY{p}{)}
            \PY{k}{return} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} prepare data}
        \PY{n}{split} \PY{o}{=} \PY{l+m+mf}{0.75}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{n}{split}\PY{p}{)}
\end{Verbatim}


    \hypertarget{plot-dataset}{%
\subsection{Plot dataset}\label{plot-dataset}}

Since the data has 4 features, 16 scatterplots (4x4) are plotted showing
the dependencies between each pair of features.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{f}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{,}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{)}\PY{p}{)}
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
            \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
                \PY{k}{if} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{0} \PY{o+ow}{and} \PY{n}{i} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sepal. length}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{va}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{24}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{5}\PY{p}{)}
                \PY{k}{elif} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{1} \PY{o+ow}{and} \PY{n}{i} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
                    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sepal. width}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{va}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{24}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{5}\PY{p}{)}
                \PY{k}{elif} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{2} \PY{o+ow}{and} \PY{n}{i} \PY{o}{==} \PY{l+m+mi}{2}\PY{p}{:}
                    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Petal. length}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{va}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{24}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{5}\PY{p}{)}
                \PY{k}{elif} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{3} \PY{o+ow}{and} \PY{n}{i} \PY{o}{==} \PY{l+m+mi}{3}\PY{p}{:}
                    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Petal. width}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{va}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{24}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{5}\PY{p}{)}
                \PY{k}{else}\PY{p}{:}
                    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{cool}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{task-1-euclidean-distance}{%
\subsection{Task 1: Euclidean
distance}\label{task-1-euclidean-distance}}

Compute Euclidean distance between two data points.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{k}{def} \PY{n+nf}{euclidean\PYZus{}distance}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Compute Euclidean distance between two data points.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Parameters}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    x1 : array, shape (4)}
         \PY{l+s+sd}{        First data point.}
         \PY{l+s+sd}{    x2 : array, shape (4)}
         \PY{l+s+sd}{        Second data point.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Returns}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    distance : float}
         \PY{l+s+sd}{        Euclidean distance between x1 and x2.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{x1} \PY{o}{\PYZhy{}} \PY{n}{x2}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \hypertarget{task-2-get-k-nearest-neighbors-labels}{%
\subsection{Task 2: get k nearest neighbors'
labels}\label{task-2-get-k-nearest-neighbors-labels}}

Get the labels of the \emph{k} nearest neighbors of the datapoint
\emph{x\_new}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{k}{def} \PY{n+nf}{get\PYZus{}neighbors\PYZus{}labels}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}new}\PY{p}{,} \PY{n}{k}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Get the labels of the k nearest neighbors of the datapoint x\PYZus{}new.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Parameters}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    X\PYZus{}train : array, shape (N\PYZus{}train, 4)}
         \PY{l+s+sd}{        Training features.}
         \PY{l+s+sd}{    y\PYZus{}train : array, shape (N\PYZus{}train)}
         \PY{l+s+sd}{        Training labels.}
         \PY{l+s+sd}{    x\PYZus{}new : array, shape (4)}
         \PY{l+s+sd}{        Data point for which the neighbors have to be found.}
         \PY{l+s+sd}{    k : int}
         \PY{l+s+sd}{        Number of neighbors to return.}
         \PY{l+s+sd}{        }
         \PY{l+s+sd}{    Returns}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    neighbors\PYZus{}labels : array, shape (k)}
         \PY{l+s+sd}{        Array containing the labels of the k nearest neighbors.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{dissimilarity} \PY{o}{=} \PY{n}{euclidean\PYZus{}distance}\PY{p}{(}\PY{n}{x\PYZus{}new}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{)}
             \PY{n}{n\PYZus{}asterisk} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{dissimilarity}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{n}{k}\PY{p}{]}
             \PY{n}{neighbors\PYZus{}labels} \PY{o}{=} \PY{n}{y\PYZus{}train}\PY{p}{[}\PY{n}{n\PYZus{}asterisk}\PY{p}{]}
             \PY{k}{return} \PY{n}{neighbors\PYZus{}labels}
\end{Verbatim}


    \hypertarget{task-3-get-the-majority-label}{%
\subsection{Task 3: get the majority
label}\label{task-3-get-the-majority-label}}

For the previously computed labels of the \emph{k} nearest neighbors,
compute the actual response. I.e. give back the class of the majority of
nearest neighbors. In case of a tie, choose the ``lowest'' label
(i.e.~the order of tie resolutions is 0 \textgreater{} 1 \textgreater{}
2).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{k}{def} \PY{n+nf}{get\PYZus{}response}\PY{p}{(}\PY{n}{neighbors\PYZus{}labels}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Predict label given the set of neighbors.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Parameters}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    neighbors\PYZus{}labels : array, shape (k)}
         \PY{l+s+sd}{        Array containing the labels of the k nearest neighbors.}
         \PY{l+s+sd}{    num\PYZus{}classes : int}
         \PY{l+s+sd}{        Number of classes in the dataset.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Returns}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    y : int}
         \PY{l+s+sd}{        Majority class among the neighbors.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{c+c1}{\PYZsh{}class\PYZus{}votes = np.zeros(num\PYZus{}classes)}
             \PY{n}{counts} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{neighbors\PYZus{}labels}\PY{p}{)}
             \PY{k}{return} \PY{n+nb}{max}\PY{p}{(}\PY{n}{counts}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{n}{counts}\PY{o}{.}\PY{n}{get}\PY{p}{)}
\end{Verbatim}


    \hypertarget{task-4-compute-accuracy}{%
\subsection{Task 4: compute accuracy}\label{task-4-compute-accuracy}}

Compute the accuracy of the generated predictions.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{k}{def} \PY{n+nf}{compute\PYZus{}accuracy}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Compute accuracy of prediction.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Parameters}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    y\PYZus{}pred : array, shape (N\PYZus{}test)}
         \PY{l+s+sd}{        Predicted labels.}
         \PY{l+s+sd}{    y\PYZus{}test : array, shape (N\PYZus{}test)}
         \PY{l+s+sd}{        True labels.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{differing\PYZus{}labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{count\PYZus{}nonzero}\PY{p}{(}\PY{n}{y\PYZus{}test} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}pred}\PY{p}{)}
             \PY{k}{return} \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{differing\PYZus{}labels}\PY{p}{)}\PY{o}{/}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{c+c1}{\PYZsh{} This function is given, nothing to do here.}
         \PY{k}{def} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{k}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Generate predictions for all points in the test set.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Parameters}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    X\PYZus{}train : array, shape (N\PYZus{}train, 4)}
         \PY{l+s+sd}{        Training features.        }
         \PY{l+s+sd}{    y\PYZus{}train : array, shape (N\PYZus{}train)}
         \PY{l+s+sd}{        Training labels.}
         \PY{l+s+sd}{    X\PYZus{}test : array, shape (N\PYZus{}test, 4)}
         \PY{l+s+sd}{        Test features.}
         \PY{l+s+sd}{    k : int}
         \PY{l+s+sd}{        Number of neighbors to consider.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Returns}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    y\PYZus{}pred : array, shape (N\PYZus{}test)}
         \PY{l+s+sd}{        Predictions for the test data.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{x\PYZus{}new} \PY{o+ow}{in} \PY{n}{X\PYZus{}test}\PY{p}{:}
                 \PY{n}{neighbors} \PY{o}{=} \PY{n}{get\PYZus{}neighbors\PYZus{}labels}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}new}\PY{p}{,} \PY{n}{k}\PY{p}{)}
                 \PY{n}{y\PYZus{}pred}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{get\PYZus{}response}\PY{p}{(}\PY{n}{neighbors}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{n}{y\PYZus{}pred}
\end{Verbatim}


    \hypertarget{testing}{%
\subsection{Testing}\label{testing}}

Should output an accuracy of 0.9473684210526315.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{c+c1}{\PYZsh{} prepare data}
         \PY{n}{split} \PY{o}{=} \PY{l+m+mf}{0.75}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{n}{split}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training set: }\PY{l+s+si}{\PYZob{}0\PYZcb{}}\PY{l+s+s1}{ samples}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test set: }\PY{l+s+si}{\PYZob{}0\PYZcb{}}\PY{l+s+s1}{ samples}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} generate predictions}
         \PY{n}{k} \PY{o}{=} \PY{l+m+mi}{3}
         \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{k}\PY{p}{)}
         \PY{n}{accuracy} \PY{o}{=} \PY{n}{compute\PYZus{}accuracy}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy = }\PY{l+s+si}{\PYZob{}0\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{accuracy}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Training set: 112 samples
Test set: 38 samples
Accuracy = 94.73684210526315

    \end{Verbatim}

    \hypertarget{problem-4}{%
\subsubsection{Problem 4}\label{problem-4}}

    \(\hat{y_a} = 0\)\\
\(\hat{y_b} = 2\)

\(p(c = 0 | x_a; T) = p(c = 1 | x_a; T) = p(c = 2 | x_a; T) = \frac{1}{3}\)\\
\(p(c = 2 | x_b; T) = \frac{2}{3}\) and
\(p(c = 0 | x_b; T) = \frac{1}{3}\)

\hypertarget{problem-5}{%
\subsubsection{Problem 5}\label{problem-5}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{predict\PYZus{}reg}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}new}\PY{p}{,} \PY{n}{d}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
            \PY{n}{y\PYZus{}predict} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
            \PY{k}{for} \PY{n}{x\PYZus{}new} \PY{o+ow}{in} \PY{n}{X\PYZus{}new}\PY{p}{:}
                \PY{n}{dissimilarity} \PY{o}{=} \PY{n}{d}\PY{p}{(}\PY{n}{x\PYZus{}new}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{X}\PY{p}{)}
                \PY{n}{n\PYZus{}asterisk} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{dissimilarity}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{k}\PY{p}{]}
                \PY{n}{y\PYZus{}predict} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{y}\PY{p}{[}\PY{n}{n\PYZus{}asterisk}\PY{p}{]}\PY{p}{)}
            \PY{k}{return} \PY{n}{y\PYZus{}predict}
\end{Verbatim}


    For \(x_a\): 3-nearest labels: {[}2.0, 0.0, 2.0{]}\\
\(\hat{y_a} = 1.0\)\\
For \(x_b\): 3-nearest labels: {[}0.0, 2.0, 1.0{]}\\
\(\hat{y_b} = 1.33\)

For \(x_a\): 3-nearest labels: {[}2.0, 0.0, 2.0{]} with distances:
{[}1.1747, 1.7464, 2.1189{]}\\
Average: 1/(1/1.1747 + 1/1.7464 + 1/2.1189) * (2.0 * 1/1.1747 + 0.0 +
2.0 * 1/2.1189) = 1.3959\\
For \(x_b\): 3-nearest labels: {[}0.0, 2.0, 1.0{]} with distances:
{[}0.6708, 2.1840, 2.4739{]}\\
Average: 1/(1/0.6708 + 1/2.1840 + 1/2.4739) * (0.0 + 2.0 * 1/2.1840 +
1.0 * 1/2.4739) = 0.5610

    \hypertarget{problem-6}{%
\subsubsection{Problem 6}\label{problem-6}}

    The \(x_{i,2}\) value is nearly the same for all data points, which
means that it can hardly contribute to the Euclidian distance in
comparison to the \(x_{i,1}\) and \(x_{i,3}\) values. A decision tree is
more accurate here, because it allows to check the features
independently from each other. However, we could also scale values and
normalize them in order to have all the dimensions in a comparable
range.

Solutions: - Data standardization(scale each feature to zero mean and
unit variance) - Use the Mahalanobis distance


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
